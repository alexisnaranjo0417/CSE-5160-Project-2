import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_similarity


#Step 2 Load dataset
dataset = pd.read_csv('dataset.csv')
# Take a random sample of 5000 rows from your dataset
sampled_dataset = dataset.sample(n=5000, random_state=42)


#Step 3 Data Exploration
#Prints the size/dimensions of the dataset
print('Data set size: ', sampled_dataset.shape, '\n')
#Prints the names of the columns/attributes of the dataset
print('Column Names: \n', sampled_dataset.columns.tolist(), '\n')


print('\nDataset looks like: ')
print(sampled_dataset.head())


#Step 4 Data Cleansing
#Clean dataset
sampled_dataset.dropna(inplace=True)
sampled_dataset.drop_duplicates(subset=['track_id'], keep='first', inplace=True)
scaler = StandardScaler()
scaled_features = scaler.fit_transform(sampled_dataset[['danceability', 'energy', 'speechiness', 'acousticness', 'instrumentalness', 'valence', 'popularity']])
pca = PCA(n_components=0.9)
x_pca = pca.fit_transform(scaled_features)

#Step 5 Model Training

#K-means Clustering Model
#List to store silhouette scores for different K values
silhouette_scores_kmeans = []

#Range of K values to test
k_values = [2, 3, 4, 5, 6, 7, 8, 9, 10]

#Perform K-Means clustering for each K and calculate silhouette score
for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
    clusters = kmeans.fit_predict(x_pca)
    # Calculate silhouette score for current K
    silhouette_avg = silhouette_score(x_pca, clusters)
    # Store the result
    silhouette_scores_kmeans.append(silhouette_avg)
    
#Print the silhouette scores for K-Means Clustering
print("K-Means Silhouette Scores")
silhouette_scores_dict = {k: score for k, score in zip(k_values, silhouette_scores_kmeans)}
for k, score in silhouette_scores_dict.items():
    print(f"K = {k}: Silhouette Score = {score:.4f}")


#Hierarchical Clustering Model
#Generate 10 random data points in 2D space, between 0..10
np.random.seed(42)
points = np.random.rand(10, 2) * 10
labels = [f'P{i+1}' for i in range(len(points))]

#Applies Agglomerative
agg_clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0, linkage='ward')

#Calculate Silhouette Scores for different numbers of clusters and save the plot for Hierarchical Clustering
silhouette_scores_hier = []
n_clusters_range = range(2, 10)
for n_clusters in n_clusters_range:
    clustering = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')
    cluster_labels = clustering.fit_predict(x_pca)
    silhouette_avg = silhouette_score(x_pca, cluster_labels)
    silhouette_scores_hier.append(silhouette_avg)

#Print the silhouette scores for Hierarchical Clustering
print("\nHierarchical Silhouette Scores")
for n_clusters, score in zip(n_clusters_range, silhouette_scores_hier):
    print(f"Clusters: {n_clusters}:  Silhouette Score: {score:.4f}")